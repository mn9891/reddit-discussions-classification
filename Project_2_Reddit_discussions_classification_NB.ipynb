{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Mini-Project 2 - Reddit discussions classification </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> Amen Memmi</div>\n",
    "<div style=\"text-align: right\"> amen.memmi@mail.mcgill.ca</div>\n",
    "<div style=\"text-align: right\">  ID: 260755070</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is prepared in the framework of Mini Project 2, Applied Machine Learning course, McGill University.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to devise a machine learning algorithm to analyze short conversations extracted from the Reddit\n",
    "website, and automatically classify them according to their topics, which include _hockey, movies, nba,\n",
    "news, nfl, politics, soccer and worldnews_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provided data is as follows: \n",
    " - The training set consists of approximately 160,000 conversations. \n",
    " - The test set consists of approximately 50,000 conversations. \n",
    " - Only training labels are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164995</th>\n",
       "      <td>&lt;speaker_1&gt; 2015 nfl draft \" i told you so \" t...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164996</th>\n",
       "      <td>&lt;speaker_1&gt; pk subban on lundqvist 's &lt;number&gt;...</td>\n",
       "      <td>hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164997</th>\n",
       "      <td>&lt;speaker_1&gt; kyrie irving and kevin love had a ...</td>\n",
       "      <td>nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164998</th>\n",
       "      <td>&lt;speaker_1&gt; miroslav klose has the broken the ...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164999</th>\n",
       "      <td>&lt;speaker_1&gt; attorney charged with having sex w...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             conversation category\n",
       "164995  <speaker_1> 2015 nfl draft \" i told you so \" t...      nfl\n",
       "164996  <speaker_1> pk subban on lundqvist 's <number>...   hockey\n",
       "164997  <speaker_1> kyrie irving and kevin love had a ...      nba\n",
       "164998  <speaker_1> miroslav klose has the broken the ...   soccer\n",
       "164999  <speaker_1> attorney charged with having sex w...     news"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_input.csv')\n",
    "data['category'] =  pd.read_csv('train_output.csv')['category']\n",
    "data = data.drop(columns={'id'})\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is to clean the conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(s):\n",
    "    \"\"\"Clean sentence\"\"\"\n",
    "    for expr in [r\"</d>\", r\"</s>\",r\"<speaker_1>\",r\"<speaker_2>\",r\"[^A-Za-z0-9(),!?\\'\\`]\"]:\n",
    "        s = re.sub(expr, \" \", s)\n",
    "    for expr in [r\"\\'s\",r\"\\'ve\",r\"\\'t\",r\"\\'re\",r\"\\'d\",r\"\\'ll\",]:\n",
    "        s = re.sub(expr, \" \"+expr[1:], s)\n",
    "    for expr in [r\",\",r\"!\",r\"\\(\",r\"\\)\"r\"\\?\"]:\n",
    "        s = re.sub(expr, \" \"+expr[1:]+\" \", s)\n",
    "    s = re.sub(r\"\\s{2,}\", \" \", s)\n",
    "    s = re.sub(r'\\S*(x{2,}|X{2,})\\S*',\"xxx\", s)\n",
    "    s = re.sub(r'[^\\x00-\\x7F]+', \"\", s)\n",
    "    return s.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"conversation\"] = data[\"conversation\"].apply(lambda x: clean_str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.conversation, data.category, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard coded Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am coding the Naive Bayes classifier using Bayes rule. First we compute the priors and likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extracting features from conversations\n",
    "count_vect = CountVectorizer()            # Convert a coonversations to a matrix of token counts\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "classes = data['category'].unique()\n",
    "prior = np.zeros(len(classes))\n",
    "likelihood = np.zeros((len(classes),X_train_counts.shape[1]))\n",
    "for c in range(len(classes)):\n",
    "    extracted_class = data[data[\"category\"]==classes[c] ].conversation\n",
    "      # Prior probabilities of each class\n",
    "    prior[c] = len(extracted_class)/X_train_counts.shape[0]\n",
    "    aux = np.asarray(count_vect.transform(extracted_class).sum(axis=0))[0]   # summing over the lines and transforming to array   \n",
    "      # features likelihood conditional probability of feature given class\n",
    "    likelihood[c] = (aux+1)/(sum(aux+1))                                     # the +1 is for Laplace smoothing\n",
    "                                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make the class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_count=count_vect.transform(X_test )\n",
    "prediction=[]\n",
    "for conv_index in range(test_count.shape[0]):\n",
    "    score=np.zeros((len(classes),1))\n",
    "    for c in range(len(classes)):\n",
    "        score[c]= np.log(prior[c])+sum(np.log(likelihood[c,test_count[conv_index].indices]))\n",
    "    prediction.append(classes[np.argmax(score)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9318787878787879"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of the hard coded NB Classifier\n",
    "np.mean(prediction == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes prediction using MultinomialNB from scikit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am creating a pipeline for the **MultinomialNB** classifier with  **CountVectorizer** (to convert a coonversations to a matrix of token counts) and **TfidfTransformer** (to transform count matrix to a normalized _tf-idf_ [term-frequency times inverse document-frequency] representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "# parameters' names are arbitrary but will be used in Grid search later\n",
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9055151515151515"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of NB Classifier\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I'm creating a list of parameters to tune. <br>\n",
    "All the parameters' names start with the classifier parameters' names (remember the arbitrary names I gave above). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.g.**:\n",
    "- vect__ngram_range; here we are telling to use unigram _ngram_range=(1,1)_ and bigrams _ngram_range=(1,2)_ and choose the one which is optimal.<br>\n",
    "- tfidf__use_idf: whether to use tfidf or not\n",
    "- clf__alpha: the bias term alpha of the clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1),(1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-1, 1e-2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next, I am creating an instance of the grid search by passing the classifier, parameters and n_jobs=-1 which tells to use multiple cores from user machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the best score and the corresponding parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9482272727272727\n",
      "{'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print (gs_clf.best_score_)\n",
    "print (gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that using bigrams, tfidf and alpha=0.01 allows better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's reevaluate the hard coded version with bigrams, trigram and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extracting features from conversations\n",
    "count_vect = CountVectorizer(ngram_range=(1,2))            # Convert a coonversations to a matrix of token counts\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "classes = data['category'].unique()\n",
    "prior = np.zeros(len(classes))\n",
    "likelihood = np.zeros((len(classes),X_train_counts.shape[1]))\n",
    "for c in range(len(classes)):\n",
    "    extracted_class = data[data[\"category\"]==classes[c] ].conversation\n",
    "      # Prior probabilities of each class\n",
    "    prior[c] = len(extracted_class)/X_train_counts.shape[0]\n",
    "    aux = np.asarray(count_vect.transform(extracted_class).sum(axis=0))[0]   # summing over the lines and transforming to array   \n",
    "      # features likelihood conditional probability of feature given class\n",
    "    likelihood[c] = (aux+1)/(sum(aux+1))                                     # the +1 is for Laplace smoothing\n",
    "test_count=count_vect.transform(X_test )\n",
    "prediction=[]\n",
    "for conv_index in range(test_count.shape[0]):\n",
    "    score=np.zeros((len(classes),1))\n",
    "    for c in range(len(classes)):\n",
    "        score[c]= np.log(prior[c])+sum(np.log(likelihood[c,test_count[conv_index].indices]))\n",
    "    prediction.append(classes[np.argmax(score)])                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9786969696969697"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of the hard coded NB Classifier\n",
    "np.mean(prediction == y_test)                                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extracting features from conversations\n",
    "count_vect = CountVectorizer(ngram_range=(1,3))            # Convert a coonversations to a matrix of token counts\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "classes = data['category'].unique()\n",
    "prior = np.zeros(len(classes))\n",
    "likelihood = np.zeros((len(classes),X_train_counts.shape[1]))\n",
    "for c in range(len(classes)):\n",
    "    extracted_class = data[data[\"category\"]==classes[c] ].conversation\n",
    "      # Prior probabilities of each class\n",
    "    prior[c] = len(extracted_class)/X_train_counts.shape[0]\n",
    "    aux = np.asarray(count_vect.transform(extracted_class).sum(axis=0))[0]   # summing over the lines and transforming to array   \n",
    "      # features likelihood conditional probability of feature given class\n",
    "    likelihood[c] = (aux+1)/(sum(aux+1))                                     # the +1 is for Laplace smoothing\n",
    "test_count=count_vect.transform(X_test )\n",
    "prediction=[]\n",
    "for conv_index in range(test_count.shape[0]):\n",
    "    score=np.zeros((len(classes),1))\n",
    "    for c in range(len(classes)):\n",
    "        score[c]= np.log(prior[c])+sum(np.log(likelihood[c,test_count[conv_index].indices]))\n",
    "    prediction.append(classes[np.argmax(score)])                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9898181818181818"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of the hard coded NB Classifier\n",
    "np.mean(prediction == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried higher than trigram but the gain is negligible while computation time goes noticibely higher. <br>\n",
    "Let's stick with trigrams and generate the prediction for the test set to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('test_input.csv')\n",
    "data_test = data_test.drop(columns={'id'})\n",
    "data_test[\"conversation\"] = data_test[\"conversation\"].apply(lambda x: clean_str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 57.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extracting features from conversations\n",
    "test_count = count_vect.transform(data_test[\"conversation\"] )\n",
    "prediction=[]\n",
    "for conv_index in range(test_count.shape[0]):\n",
    "    score=np.zeros((len(classes),1))\n",
    "    for c in range(len(classes)):\n",
    "        score[c]= np.log(prior[c])+sum(np.log(likelihood[c,test_count[conv_index].indices]))\n",
    "    prediction.append(classes[np.argmax(score)])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25010</th>\n",
       "      <td>25010</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48790</th>\n",
       "      <td>48790</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44715</th>\n",
       "      <td>44715</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id category\n",
       "25010  25010     news\n",
       "48790  48790      nfl\n",
       "44715  44715   movies"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame({'id': range(len(prediction)), 'category':prediction})\n",
    "prediction_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We export the prediction dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv('prediction_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
